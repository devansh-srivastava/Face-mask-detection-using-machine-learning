	<!DOCTYPE html>
	<html>
	<head>
		<title></title>
		<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
	
		<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-wasm/dist/tf-backend-wasm.js"></script>
		<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" integrity="sha384-JcKb8q3iqJ61gNV9KGb8thSsNjpSL0n8PARn9HuZOnIxN0hoP+VmmDGMN5t9UJ0Z" crossorigin="anonymous">
		<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.0/css/all.css" integrity="sha384-lZN37f5QGtY3VHgisS14W3ExzMWZxybE1SJSEsQp9S+oqd12jhcu+A56Ebc1zFSJ" crossorigin="anonymous">
	</head>
	<style>
	body{
		padding: 50px;
	}
	h2{
		font-weight: bolder;
	}
	.navbar{
	 justify-content: center;
	}
	.nav{
		height: 50px;
		width: 700px;
		border-radius: 20px;
		background: linear-gradient(to left, #f2709c,#ff9472);
		color:black;
		display: flex;
		align-items: center;
		justify-content: center;
 
	}
	.iconn{
		padding: 10px;
		margin-top: -5px;
		
	}
	img{
		height: 30px;
	}
	
	#video{
		margin:auto;
		display:inline-block;
		max-height: 600px;
		max-width: 600px;
	}
	#output{
		margin:auto;
		position:relative;
		max-height: 600px;
		max-width: 600px;
		top:-480px;
		left:10px
	}

	.progress {
		margin-left: 35vw;
	height: 30px;
	width: 300px;
	align-items: center;
	align-self: center;
	text-align: center;
	border-radius: 20px;
	background: linear-gradient(to left, #f2709c,#ff9472);
	color: #fff;
	display: flex;
	justify-content: center;
  align-items: center;
  box-shadow: 0 3px 3px -5px #f2709c, 0 2px 5px #f2709c;
	}
		
	</style>
	<body >
		<div class="container1" >
			<header >
				<nav class="navbar" >
					<div class= " nav"><div class="iconn"><img src="https://img.icons8.com/android/24/000000/camera.png"/>	</div>
					<h2>  Face Mask Detection By Devansh</h2>
				</div>
				
			</nav>
			</header>
		
		</div>
		<div class="progress">
			Loading Model
		</div>
		
		<div class="container ">
			<section>
				<div class="row bg-light">
				<video id="video" playsinline class="border "></video>
				<canvas id="output" class="canvas-output"></canvas>
				
			</div> 
			
			</section>
		</div>
		
		
		<script>
		
		var model, mask_model, ctx, videoWidth, videoHeight, canvas;
		const video = document.getElementById('video');
		const state = {
		backend: 'wasm'
		};
		async function setupCamera() {
			const stream = await navigator.mediaDevices.getUserMedia({
				'audio': false,
				'video': { facingMode: 'user' },
			});
			video.srcObject = stream;
			return new Promise((resolve) => {
				video.onloadedmetadata = () => {
				resolve(video);
				};
			});
		}


		const renderPrediction = async () => {
			tf.engine().startScope()
			ctx.clearRect(0, 0, canvas.width, canvas.height);
			//estimatefaces model takes in 4 parameter (1) video, returnTensors, flipHorizontal, and annotateBoxes
			const predictions = await model.estimateFaces(video, true,false,false);
			const offset = tf.scalar(127.5);
			//check if prediction length is more than 0
			if (predictions.length > 0) {
				//clear context
				
				for (let i = 0; i < predictions.length; i++) {
					var text=""
					var start = predictions[i].topLeft.arraySync();
					var end = predictions[i].bottomRight.arraySync();
					var size = [end[0] - start[0], end[1] - start[1]];
					if(videoWidth<end[0] && videoHeight<end[0]){
						console.log("image out of frame")
						continue
					}
					var inputImage = tf.browser.fromPixels(video).toFloat()
					inputImage = inputImage.sub(offset).div(offset);
					inputImage=inputImage.slice([parseInt(start[1]),parseInt(start[0]),0],[parseInt(size[1]),parseInt(size[0]),3])
					inputImage=inputImage.resizeBilinear([224,224]).reshape([1,224,224,3])
					result=mask_model.predict(inputImage).dataSync()
					result= Array.from(result)
					ctx.beginPath()
					if (result[1]>result[0]){
						//no mask on
						ctx.strokeStyle="red"
						ctx.fillStyle = "red";
						text = "No Mask: "+(result[1]*100).toPrecision(3).toString()+"%";
					}else{
						//mask on
						ctx.strokeStyle="green"
						ctx.fillStyle = "green";
						text = "Mask: "+(result[0]*100).toPrecision(3).toString()+"%";
					}
					ctx.lineWidth = "4"
					ctx.rect(start[0], start[1],size[0], size[1])
					ctx.stroke()
					ctx.font = "bold 15pt sans-serif";
					ctx.fillText(text,start[0]+5,start[1]+20)
				}     
			}
			//update frame
			requestAnimationFrame(renderPrediction);
			tf.engine().endScope()
		};

		const setupPage = async () => {
			await tf.setBackend(state.backend);
			await setupCamera();
			video.play();

			videoWidth = video.videoWidth;
			videoHeight = video.videoHeight;
			video.width = videoWidth;
			video.height = videoHeight;

			canvas = document.getElementById('output');
			canvas.width = videoWidth;
			canvas.height = videoHeight;
			ctx = canvas.getContext('2d');
			ctx.fillStyle = "rgba(255, 0, 0, 0.5)"; 
	model = await blazeface.load();
			
			mask_model = await tf.loadLayersModel('models/model.json');
			$(".progress").hide();
		

		renderPrediction();
		};

		setupPage();

	</script>
	<script src="js/blazeface.js" type="text/javascript"></script>
	<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
	<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js" integrity="sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN" crossorigin="anonymous"></script>
	<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/handpose"></script>

	</body>

	</html>